# Credit Risk Analysis Report
## Purpose: 
#### Used imbalanced-learn and scikit-learn libraries (specifically using LogisticRegression classifier), to evaluate multiple machine learning models by using resampling to determine which is better at predicting credit risk, including: oversampling RandomOverSampler and SMOTE algorithms, undersampling ClusterCentroids algorithm and combinatorial (over and undersampling) approach SMOTENN, Balanced Random Forest Classifier and Easy Ensemble AdaBoost Classifier.  The algorithms were used to resample the dataset, view the count of the target data classes, train the logistics regression classifier, calculate the balanced accuracy score, generate a confusion matrix, and generate a classification report.

## Deliverable 1: Use Resampling Models to Predict Credit Risk

### Oversampling:  RandomOverSampler

 - An Accuracy Score for the Model
![Mod17_D1.1.A_Accuracy_Score_RandomOverSampler.PNG](https://github.com/Tara-Lightner/Credit_Risk_Analysis/blob/main/Module-17-Challenge-Resources/Mod17_D1.1.A_Accuracy_Score_RandomOverSampler.PNG)

 - A Confusion Matrix
![Mod17_D1.2.A_Confusion_Matirx_RandomOverSampler.PNG](https://github.com/Tara-Lightner/Credit_Risk_Analysis/blob/main/Module-17-Challenge-Resources/Mod17_D1.2.A_Confusion_Matirx_RandomOverSampler.PNG)

 - An Imbalanced Classification
![Mod17_D1.3.B_Imbalanced_Classification_Report_RandomOverSampler.PNG](https://github.com/Tara-Lightner/Credit_Risk_Analysis/blob/main/Module-17-Challenge-Resources/Mod17_D1.3.A_Imbalanced_Classification_Report_RandomOverSampler.PNG)

### Oversampling: SMOTE
 - An Accuracy Score for the Model
![Mod17_D1.1.B_Accuracy_Score_SMOTE.PNG](https://github.com/Tara-Lightner/Credit_Risk_Analysis/blob/main/Module-17-Challenge-Resources/Mod17_D1.1.B_Accuracy_Score_SMOTE.PNG)

 - A Confusion Matrix
![Mod17_D1.2.B_Confusion_Matirx_SMOTE.PNG](https://github.com/Tara-Lightner/Credit_Risk_Analysis/blob/main/Module-17-Challenge-Resources/Mod17_D1.2.B_Confusion_Matirx_SMOTE.PNG)

 - An Imbalanced Classification
![Mod17_D1.3.B_Imbalanced_Classification_Report_SMOTE.PNG](https://github.com/Tara-Lightner/Credit_Risk_Analysis/blob/main/Module-17-Challenge-Resources/Mod17_D1.3.B_Imbalanced_Classification_Report_SMOTE.PNG)

### Undersampling: ClusterCentroids
 - An Accuracy Score for the Model
![Mod17_D1.1.C_Accuracy_Score_ClusterCentroids.PNG](https://github.com/Tara-Lightner/Credit_Risk_Analysis/blob/main/Module-17-Challenge-Resources/Mod17_D1.1.C_Accuracy_Score_ClusterCentroids.PNG)

 - A Confusion Matrix
![Mod17_D1.2.C_Confusion_Matirx_ClusterCentroids.PNG](https://github.com/Tara-Lightner/Credit_Risk_Analysis/blob/main/Module-17-Challenge-Resources/Mod17_D1.2.C_Confusion_Matirx_ClusterCentroids.PNG)

 - An Imbalanced Classification
![Mod17_D1.3.C_Imbalanced_Classification_Report_ClusterCentroids.PNG](https://github.com/Tara-Lightner/Credit_Risk_Analysis/blob/main/Module-17-Challenge-Resources/Mod17_D1.3.C_Imbalanced_Classification_Report_ClusterCentroids.PNG)

## Deliverable 2: Use the SMOTEENN Algorithm to Predict Credit Risk
### Combinatorial (Oversampling & Undersampling) SMOTEENN:
- An Accuracy Score for the Model
![Mod17_D1.1.A_Accuracy_Score_SMOTEENN.PNG](https://github.com/Tara-Lightner/Credit_Risk_Analysis/blob/main/Module-17-Challenge-Resources/Deliverable2/Mod17_D1.1.A_Accuracy_Score_SMOTEENN.PNG)

- A Confusion Matrix
![Mod17_D1.2.A_Confusion_Matirx_SMOTEENN.PNG](https://github.com/Tara-Lightner/Credit_Risk_Analysis/blob/main/Module-17-Challenge-Resources/Deliverable2/Mod17_D1.2.A_Confusion_Matirx_SMOTEENN.PNG)

 - An Imbalanced Classification
![Mod17_D1.3.A_Imbalanced_Classification_Report_SMOTEENN.PNG](https://github.com/Tara-Lightner/Credit_Risk_Analysis/blob/main/Module-17-Challenge-Resources/Deliverable2/Mod17_D1.3.A_Imbalanced_Classification_Report_SMOTEENN.PNG)

## Deliverable 3: Use Ensemble Classifiers to Predict Credit Risk

### Credit Risk:  Balanced Random Forest Classifier Ensemble
- An Accuracy Score for the Model
![Mod17_D3.1.A_Accuracy_Score_Balanced_Random_Ensemble.PNG](https://github.com/Tara-Lightner/Credit_Risk_Analysis/blob/main/Module-17-Challenge-Resources/Deliverable3/Mod17_D3.1.A_Accuracy_Score_Balanced_Random_Ensemble.PNG)

- A Confusion Matrix
![Mod17_D3.2.A_Confusion_Matirx_Balanced_Random_Ensemble.PNG](https://github.com/Tara-Lightner/Credit_Risk_Analysis/blob/main/Module-17-Challenge-Resources/Deliverable3/Mod17_D3.2.A_Confusion_Matirx_Balanced_Random_Ensemble.PNG)

 - An Imbalanced Classification
![Module-17-Challenge-Resources/Deliverable3/Mod17_D3.3.A_Imbalanced_Classification_Report_Balanced_Random_Ensemble.PNG](https://github.com/Tara-Lightner/Credit_Risk_Analysis/blob/main/Module-17-Challenge-Resources/Deliverable3/Mod17_D3.3.A_Imbalanced_Classification_Report_Balanced_Random_Ensemble.PNG)

### Credit Risk:  Easy Ensemble
- An Accuracy Score for the Model
![Mod17_D3.1.B_Accuracy_Score_Easy_Ensemble.PNG](https://github.com/Tara-Lightner/Credit_Risk_Analysis/blob/main/Module-17-Challenge-Resources/Deliverable3/Mod17_D3.1.B_Accuracy_Score_Easy_Ensemble.PNG)

- A Confusion Matrix
![Module-17-Challenge-Resources/Deliverable3/Mod17_D3.2.B_Confusion_Matirx_Easy_Ensemble.PNG](https://github.com/Tara-Lightner/Credit_Risk_Analysis/blob/main/Module-17-Challenge-Resources/Deliverable3/Mod17_D3.2.B_Confusion_Matirx_Easy_Ensemble.PNG)

- An Imbalanced Classification
![Mod17_D3.3.B_Imbalanced_Classification_Report_Easy_Ensemble.PNG](https://github.com/Tara-Lightner/Credit_Risk_Analysis/blob/main/Module-17-Challenge-Resources/Deliverable3/Mod17_D3.3.B_Imbalanced_Classification_Report_Easy_Ensemble.PNG)

## Results: 

### Balanced Accuracy Scores:
Note:  The closer the balanced accuracy is to 1, the better the model is able to correctly classify observations.
#### 1.) Easy Ensemble AdaBoost Classifier Accuracy Score = 0.93166
#### 2.) Balanced Random Forest Classifier Accuracy Score = 0.7885
#### 3.) Oversampling SMOTE Accuracy Score = 0.6622
#### 4.) Oversampling RandomOverSampler Accuracy Score = 0.6573
#### 5.) Combinatorial (over and undersampling SMOTENN Accuracy Score = 0.6392
#### 6.) Undersampling ClusterCentroids Accuracy Score = 0.5442



### Precision:
Note: Precision is the measure of how reliable a positive classification is. A low precision is indicative of a large number of false positives.

- Oversampling RandomOverSampler, Oversampling SMOTE, Undersampling ClusterCentroids & Combinatorial (over and undersampling SMOTENN)

high risk = 0.01
low risk = 1.00
average/total = 0.99

- Balanced Random Forest Classifier
high risk = 0.03
low risk = 1.00
average/total = 0.99

- Easy Ensemble AdaBoost Classifier
high risk = 0.09
low risk = 1.00
average/total = 0.99

The precision for Oversampling RandomOverSampler, Oversampling SMOTE, Undersampling ClusterCentroids & Combinatorial (over and undersampling SMOTENN) Algorithms all have a high risk of 0.01 and a low risk of 1.00.  Additionally, both Ensembles have a low risk of 1.00.  The Balance Random Forest Classifier has a high risk of 0.03 and the Easy Ensemble AdaBoost Classifier has a high risk of 0.09. Therefore the best match is Easy Ensemble AdaBoost Classifier, followed by the Balanced Random Forest Classifier, then the remainder of the algorithms.

### Recall (a.k.a. sensitivity) Scores
Note: Recall is the ability of the classifier to find all the positive samples. A low recall is indicative of a large number of false negatives.

- Oversampling RandomOverSampler
high risk = 0.71
low risk = 0.60
average/total = 0.60

- Oversampling SMOTE 
high risk = 0.63
low risk = 0.69
average/total = 0.69

- Undersampling ClusterCentroids
high risk = 0.69
low risk = 0.40
average/total = 0.40

- Combinatorial (over and undersampling SMOTENN
high risk = 0.70
low risk = 0.58
average/total = 0.58

- Balanced Random Forest Classifier
high risk = 0.70
low risk = 0.87
average/total = 0.87

- Easy Ensemble AdaBoost Classifier
high risk = 0.92
low risk = 0.94
average/total = 0.94

In order of average/total recall the best results were as follows: 
#### 1.)  Easy Ensemble AdaBoost Classifier average/total = 0.94
#### 2.) Balanced Random Forest Classifier average/total = 0.87
#### 3.) Oversampling SMOTE average/total = 0.69
#### 4.) Oversampling RandomOverSampler average/total = 0.60
#### 5.) Combinatorial (over and undersampling SMOTENN = average/total = 0.58
#### 6.) Undersampling ClusterCentroids average/total = 0.40

## Summary:
Easy Ensemble is the best fitting algorithm on all three accounts of accuracy, precision, and sensitivity. To summarize it has an accuracy Score = 0.93166 a high risk of 0.09., an average/total recall of = 0.94.  

## Deliverable 4: A Written Report on the Credit Risk Analysis (README.md) 

 -- This completed file
